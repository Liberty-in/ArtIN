# -*- coding: utf-8 -*-
"""train_net.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hCuhQTh2nIp8XYjSpbSVto8QHklydwWy
"""

import torch
import torch.optim as optim
import torch.nn as nn
criterion = nn.CrossEntropyLoss()# функция потерь
def get_optimizer(net):
  optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)#преобразование весоа
  return optimizer

def train(trainloader, net):
  optimizer = get_optimizer(net)
  for epoch in range(2):  # loop over the dataset multiple times

      running_loss = 0.0
      for i, data in enumerate(trainloader, 0):
          # get the inputs; data is a list of [inputs, labels]
          inputs, labels = data

          # zero the parameter gradients
          optimizer.zero_grad()

          # forward + backward + optimize
          outputs = net(inputs)
          loss = criterion(outputs, labels)
          loss.backward()
          optimizer.step()#уменьшение вемлов на гградиент

          # print statistics
          running_loss += loss.item()
          if i % 2000 == 1999:    # print every 2000 mini-batches
              print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')
              running_loss = 0.0

  print('Finished Training')

